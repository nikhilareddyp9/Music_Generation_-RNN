{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNUKWUpfdvThrFVV1WW+vei",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikhilareddyp9/Music_Generation_-RNN/blob/main/Music_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQnUTfCwTkcq"
      },
      "outputs": [],
      "source": [
        "! pip install  music21"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import re \n",
        "import numpy \n",
        "import pandas\n",
        "\n",
        "import music21\n",
        "from glob import glob\n",
        "import IPython\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from music21 import converter, instrument, note, chord, stream\n"
      ],
      "metadata": {
        "id": "Wql8soUFVOml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "songs = glob('Jazz/*.mid')\n",
        "songs = songs[:3]"
      ],
      "metadata": {
        "id": "57a82L99VVlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install -y fluidsynth\n",
        "!pip install --upgrade pyfluidsynth\n",
        "!pip install pretty_midi"
      ],
      "metadata": {
        "id": "IXfHV_DkVbuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pretty_midi as musical_inf\n",
        "\n",
        "import datetime\n",
        "import glob\n",
        "import numpy\n",
        "import pathlib\n",
        "import fluidsynth\n",
        "import pandas\n",
        "import seaborn as sns\n",
        "import collections\n",
        "import tensorflow\n",
        "\n",
        "\n",
        "from IPython import display as show\n",
        "from matplotlib import pyplot\n",
        "from typing import Optional\n"
      ],
      "metadata": {
        "id": "GNraONsMVetl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "randomseed = 42\n",
        "tensorflow.random.set_seed(randomseed)\n",
        "numpy.random.seed(randomseed)\n"
      ],
      "metadata": {
        "id": "0Jp_pJYxV9Xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sampling rate for audio playback\n",
        "instance_hertz = 16000\n",
        "\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import os as pull\n",
        "\n",
        "directory = 'data/maestro-v2.0.0'\n",
        "if not pull.path.exists(directory):\n",
        "    pull.makedirs(directory)\n",
        "    url = 'https://storage.googleapis.com/magentadata/datasets/maestro/v2.0.0/maestro-v2.0.0-midi.zip'\n",
        "    urllib.request.urlretrieve(url, f'{directory}/maestro-v2.0.0-midi.zip')\n",
        "    with zipfile.ZipFile(f'{directory}/maestro-v2.0.0-midi.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall(directory)\n",
        "\n",
        "folders = []\n",
        "for I, _, cases in pull.walk(directory):\n",
        "    for z in cases:\n",
        "        if z.endswith('.mid') or z.endswith('.midi'):\n",
        "            folders.append(pull.path.join(I, z))\n",
        "\n",
        "print('Number of music files scrutinized:', len(folders))\n",
        "\n",
        "instancefile = folders[1]\n",
        "print(instancefile)\n",
        "prettyMIDI = musical_inf.PrettyMIDI(instancefile)\n",
        "\n",
        "def show_phonic(prettyMIDI: musical_inf.PrettyMIDI, seconds=35):\n",
        "    duration = prettyMIDI.get_end_time()\n",
        "    if seconds > duration:\n",
        "        seconds = duration\n",
        "    samples = int(seconds * instance_hertz)\n",
        "    waveform = prettyMIDI.fluidsynth(fs=instance_hertz)\n",
        "    waveform_short = waveform[:samples]\n",
        "    return show.Audio(waveform_short, rate=instance_hertz)\n",
        "\n",
        "show_phonic(prettyMIDI)\n",
        "\n",
        "instruments_used = prettyMIDI.instruments\n",
        "print('Number of instruments:', len(instruments_used))\n",
        "if len(instruments_used) > 0:\n",
        "    instrument = instruments_used[0]\n",
        "    toolname= musical_inf.program_to_instrument_name(instrument.program)\n",
        "    print('Tool used name:', toolname)\n",
        "else:\n",
        "    print('No Tools found in the PrettyMIDI object.')\n"
      ],
      "metadata": {
        "id": "EImF2ICcWBcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade music21"
      ],
      "metadata": {
        "id": "Zbl1wcbHWM0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k_pole, score in enumerate(instrument.notes[:10]):\n",
        "  notesname = musical_inf.note_number_to_name(score.pitch)\n",
        "  timepernote = float(score.end - score.start)\n",
        "  print(str(k_pole) +': '+'Note= '+str(notesname)+' Pitch= '+str(score.pitch)+' Time= '+str(round(timepernote,3)))\n",
        "\n",
        "def convert_midis2notes(midi: str) -> pandas.DataFrame:\n",
        "    prettyMIDI = musical_inf.PrettyMIDI(midi)\n",
        "    tool = prettyMIDI.instruments[0]\n",
        "    notes = collections.defaultdict(list)\n",
        "\n",
        "    sorted_notes = sorted(tool.notes, key=lambda note: note.start)\n",
        "    prev_start = sorted_notes[0].start\n",
        "\n",
        "    for note in sorted_notes:\n",
        "        start = note.start\n",
        "        end = note.end\n",
        "        notes['pitch'].append(note.pitch)\n",
        "        notes['start'].append(start)\n",
        "        notes['end'].append(end)\n",
        "        notes['step'].append(start - prev_start)\n",
        "        notes['duration'].append(end - start)\n",
        "        prev_start = start\n",
        "\n",
        "    return pandas.DataFrame({name: numpy.array(value) for name, value in notes.items()})\n",
        "\n",
        "rawtranscription = convert_midis2notes(instancefile)\n",
        "rawtranscription.head()\n",
        "\n",
        "def note_numbers2names(note_numbers: numpy.ndarray) -> numpy.ndarray:\n",
        "    return numpy.vectorize(musical_inf.note_number_to_name)(note_numbers)\n",
        "\n",
        "transcriptionsample = note_numbers2names(rawtranscription['pitch'])[:10]\n",
        "transcriptionsample[:10]\n",
        "\n",
        "def show_piano_roll(df_notes: pandas.DataFrame, max_notes: Optional[int] = None):\n",
        "    if max_notes:\n",
        "        plot_title,notes_to_plot = f'Begin {max_notes} Transcription',df_notes.iloc[:max_notes]\n",
        "    else:\n",
        "        plot_title,notes_to_plot  = f'Full audio',df_notes\n",
        "    pyplot.figure(figsize=(21, 5))\n",
        "    pitch_array = numpy.stack([notes_to_plot['pitch'], notes_to_plot['pitch']], axis=0)\n",
        "    time_array = numpy.stack([notes_to_plot['start'], notes_to_plot['end']], axis=0)\n",
        "    pyplot.plot(time_array[:, :max_notes], pitch_array[:, :max_notes], color=\"r\", marker=\"|\")\n",
        "    pyplot.xlabel('Time in secs')\n",
        "    pyplot.ylabel('Pitch')\n",
        "    _ = pyplot.title(plot_title)\n"
      ],
      "metadata": {
        "id": "K0ZfO8fCWTUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_piano_roll(rawtranscription, max_notes=100)\n",
        "\n",
        "show_piano_roll(rawtranscription)\n"
      ],
      "metadata": {
        "id": "K7kue2NWWa2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_note_distributions(note_df: pandas.DataFrame, fall: float = 2.5):\n",
        "    fig, axis = pyplot.subplots(1, 3, figsize=(15,5))\n",
        "\n",
        "\n",
        "    axis[0].hist(note_df['pitch'], bins=19)\n",
        "    axis[0].set_xlabel('Pitch')\n",
        "    axis[0].set_ylabel('Count')\n",
        "\n",
        "    max_step = numpy.percentile(note_df['step'], 100 - fall)\n",
        "    axis[1].hist(note_df['step'], bins=numpy.linspace(0, max_step, 20))\n",
        "    axis[1].set_xlabel('Step')\n",
        "    axis[1].set_ylabel('Count')\n",
        "\n",
        "    max_duration = numpy.percentile(note_df['duration'], 100 - fall)\n",
        "    axis[2].hist(note_df['duration'], bins=numpy.linspace(0, max_duration, 20))\n",
        "    axis[2].set_xlabel('Duration')\n",
        "    axis[2].set_ylabel('Count')\n",
        "\n",
        "    pyplot.show()\n"
      ],
      "metadata": {
        "id": "p789ruYGWfQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_note_distributions(rawtranscription)"
      ],
      "metadata": {
        "id": "fe572A-_WfTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_midi_file(notes_df: pandas.DataFrame, result: str, toolused: str, speed: int = 100) -> musical_inf.PrettyMIDI:\n",
        "    prettyMIDI = musical_inf.PrettyMIDI()\n",
        "    instrument_program = musical_inf.instrument_name_to_program(toolused)\n",
        "    instrument_obj = musical_inf.Instrument(program=instrument_program)   \n",
        "    prev_note_end = 0\n",
        "    for idx, I in notes_df.iterrows():\n",
        "        start_time,pitch = prev_note_end + I['step'],int(I['pitch'])\n",
        "        end_time = start_time + I['duration']\n",
        "        new_note = musical_inf.Note(velocity=speed,pitch=pitch,start=start_time,end=end_time)\n",
        "        instrument_obj.notes.append(new_note)\n",
        "        prev_note_end = end_time\n",
        "    prettyMIDI.instruments.append(instrument_obj)\n",
        "    prettyMIDI.write(result)    \n",
        "    return prettyMIDI\n"
      ],
      "metadata": {
        "id": "UFTtbgAPWfW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instancefile = 'example.midi'\n",
        "example_prettyMIDI = create_midi_file(rawtranscription, result=instancefile, toolused=toolname)\n",
        "\n",
        "show_phonic(example_prettyMIDI)\n"
      ],
      "metadata": {
        "id": "mH5zo05lWsWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TO_PARSE = 5\n",
        "\n",
        "\n",
        "transcription_array = []\n",
        "for file_path in folders[:TO_PARSE]:\n",
        "    transcription = convert_midis2notes(file_path)\n",
        "    transcription_array.append(transcription)\n",
        "\n",
        "\n",
        "transcription_df = pandas.concat(transcription_array)\n",
        "num_transcription = len(transcription_df)\n",
        "print(f\"Count of transcription: {num_transcription}\")\n"
      ],
      "metadata": {
        "id": "13AVCKyPWxk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = ['pitch', 'step', 'duration']\n",
        "features = numpy.stack([transcription_df[feature] for feature in feature_names], axis=1)\n",
        "transcription_ds = tensorflow.data.Dataset.from_tensor_slices(features)\n",
        "\n",
        "\n",
        "print(f\"Dataset element spec: {transcription_ds.element_spec}\")\n"
      ],
      "metadata": {
        "id": "N0MHmGDYW6KI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seriessize = 25\n",
        "vocablen = 128\n",
        "\n",
        "def generate_transcription(processingfile: tensorflow.data.Dataset, seriessize: int, vocablen: int = 128) -> tensorflow.data.Dataset:\n",
        "    \"\"\"Returns a TensorFlow dataset of sequence and label examples.\"\"\"\n",
        "    seriessize = seriessize + 1\n",
        "\n",
        "\n",
        "    Xfile = processingfile.window(seriessize, shift=1, stride=1, drop_remainder=True)\n",
        "\n",
        "\n",
        "    scruten = lambda x: x.batch(seriessize, drop_remainder=True)\n",
        "    sequences = Xfile.flat_map(scruten)\n",
        "\n",
        "\n",
        "    def normalize(y):\n",
        "        y = y / [vocablen, 1.0, 1.0]\n",
        "        return y\n",
        "\n",
        "\n",
        "    def divide_transcription(series):\n",
        "        data = series[:-1]\n",
        "        Dnames = series[-1]\n",
        "        names = {key: Dnames[i] for i, key in enumerate(feature_names)}\n",
        "\n",
        "        return normalize(data), names\n",
        "\n",
        "\n",
        "    return sequences.map(divide_transcription, num_parallel_calls=tensorflow.data.AUTOTUNE)\n",
        "dl_int = generate_transcription(transcription_ds, seriessize, vocablen)\n",
        "dl_int.element_spec\n",
        "\n",
        "for sequence, tl in dl_int.take(1):\n",
        "    print('Arrangement of the series:', sequence.shape)\n",
        "    print('Highs in the sequence (15):', sequence[0: 15])\n",
        "    print()\n",
        "    print('target label:', tl)\n"
      ],
      "metadata": {
        "id": "KcN6-LLOW9xE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size_of_batch = 64\n",
        "size_of_buffer = num_transcription - seriessize  \n",
        "ds_train = (dl_int\n",
        "            .shuffle(size_of_buffer)\n",
        "            .batch(size_of_batch, drop_remainder=True)\n",
        "            .cache()\n",
        "            .prefetch(tensorflow.data.experimental.AUTOTUNE))\n",
        "ds_train.element_spec\n",
        "\n",
        "def calculate_meansquareerror_pp(y_true_labels: tensorflow.Tensor, y_predicted_labels: tensorflow.Tensor):\n",
        "  \"\"\"Calculates mean squared error loss with positive pressure.\"\"\"\n",
        "  meansqureerror_loss = (y_true_labels - y_predicted_labels) ** 2\n",
        "  pp = 10 * tensorflow.maximum(-y_predicted_labels, 0.0)\n",
        "  return tensorflow.reduce_mean(meansqureerror_loss + pp)\n"
      ],
      "metadata": {
        "id": "nbMVgvEoXI4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq = (seriessize, 3)\n",
        "rate_of_learn_value = 0.005\n",
        "\n",
        "inputlayer = tensorflow.keras.Input(seq)\n",
        "lstm_layer = tensorflow.keras.layers.LSTM(128)(inputlayer)\n",
        "\n",
        "output_layers = {\n",
        "  'pitch': tensorflow.keras.layers.Dense(128, name='pitch')(lstm_layer),\n",
        "  'step': tensorflow.keras.layers.Dense(1, name='step')(lstm_layer),\n",
        "  'duration': tensorflow.keras.layers.Dense(1, name='duration')(lstm_layer),\n",
        "}\n",
        "\n",
        "mod_generated = tensorflow.keras.Model(inputlayer, output_layers)\n",
        "\n",
        "loss_fn = {\n",
        "      'pitch': tensorflow.keras.losses.SparseCategoricalCrossentropy(\n",
        "          from_logits=True),\n",
        "      'step': calculate_meansquareerror_pp,\n",
        "      'duration': calculate_meansquareerror_pp,\n",
        "}\n",
        "\n",
        "shaper = tensorflow.keras.optimizers.Adam(learning_rate=rate_of_learn_value)\n",
        "\n",
        "mod_generated.compile(loss=loss_fn, optimizer=shaper)\n",
        "\n",
        "mod_generated.summary()\n"
      ],
      "metadata": {
        "id": "fzXVINffXQrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = mod_generated.evaluate(ds_train, return_dict=True)\n",
        "mod_generated.compile(loss=loss_fn,loss_weights={'pitch': 0.05,'step': 1.0,'duration':1.0,},optimizer=shaper,)\n",
        "\n",
        "CB = [\n",
        "    tensorflow.keras.callbacks.ModelCheckpoint(\n",
        "        filepath='./training_checkpoints/ckpt_{epoch}',\n",
        "        save_weights_only=True),\n",
        "    tensorflow.keras.callbacks.EarlyStopping(\n",
        "        verbose=1,\n",
        "        monitor='loss',\n",
        "        restore_best_weights=True,\n",
        "        patience=5),\n",
        "]\n"
      ],
      "metadata": {
        "id": "m7PC48cKXW1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "%%time\n",
        "epochs = 50\n",
        "result = mod_generated.fit(ds_train,epochs=epochs,callbacks=CB,)\n",
        "\n",
        "pyplot.plot(result.epoch,result.history['loss'], label='total loss')\n",
        "pyplot.show()\n"
      ],
      "metadata": {
        "id": "sNCoqxoVXa6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_note(preds: numpy.ndarray, \n",
        "                  kmodel: tensorflow.keras.Model, \n",
        "                  newtemp: float = 1.0) -> tuple[int, float, float]:\n",
        "    \"\"\"Generates a note as a tuple of (pitch, step, duration), using a trained sequence model.\"\"\"\n",
        "\n",
        "    assert newtemp > 0\n",
        "\n",
        "    data = tensorflow.expand_dims(preds, 0)\n",
        "\n",
        "    outputs_notes = kmodel.predict(data)\n",
        "    logits = outputs_notes['pitch']\n",
        "    stepp = outputs_notes['step']\n",
        "    t_insecs = outputs_notes['duration']\n",
        " \n",
        "    logits /= newtemp\n",
        "    ptch = tensorflow.random.categorical(logits, num_samples=1)\n",
        "    ptch = tensorflow.squeeze(ptch, axis=-1)\n",
        "    t_time = tensorflow.squeeze(t_insecs, axis=-1)\n",
        "    stepp = tensorflow.squeeze(stepp, axis=-1)\n",
        "\n",
        "\n",
        "    stepp = tensorflow.maximum(0, stepp)\n",
        "    t_insecs = tensorflow.maximum(0, t_time)\n",
        "\n",
        "    return int(ptch), float(stepp), float(t_insecs)\n"
      ],
      "metadata": {
        "id": "y9LjGanzXmSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_degree = 2.0\n",
        "num_of_preds = 120\n",
        "\n",
        "sampnote = numpy.stack([rawtranscription[I] for I in feature_names], axis=1)\n",
        "\n",
        "\n",
        "data_trans = (\n",
        "    sampnote[:seriessize] / numpy.array([vocablen, 1, 1]))\n",
        "\n",
        "new_notes = []\n",
        "pbegin = 0\n",
        "for _ in range(num_of_preds):\n",
        "  pitch, step, duration = predict_next_note(data_trans, mod_generated, new_degree)\n",
        "  begin_time = pbegin + step\n",
        "  final_time = begin_time + duration\n",
        "  data = (pitch, step, duration)\n",
        "  new_notes.append((*data, begin_time, final_time))\n",
        "  data_trans = numpy.delete(data_trans, 0, axis=0)\n",
        "  data_trans = numpy.append(data_trans, numpy.expand_dims(data, 0), axis=0)\n",
        "  pbegin = begin_time\n"
      ],
      "metadata": {
        "id": "V1SLW5M8Xzaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_notes_df = pandas.DataFrame(new_notes, columns=(*feature_names, 'start', 'end'))\n",
        "\n",
        "new_notes_df.head(10)\n"
      ],
      "metadata": {
        "id": "FyRtU3WVXzct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultfile = 'output.mid'\n",
        "resultMIDI = create_midi_file(\n",
        "    new_notes_df, result=resultfile, toolused=toolname)\n",
        "show_phonic(resultMIDI)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(resultfile)\n"
      ],
      "metadata": {
        "id": "2sMmAe7xXzgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_piano_roll(new_notes_df)"
      ],
      "metadata": {
        "id": "PFBdHYtUYBqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_note_distributions(new_notes_df)"
      ],
      "metadata": {
        "id": "n4yUGaPcYBt_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}